{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.config.model_args import ModelArgs\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import torch\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "import pathlib\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from typing import List, Tuple\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.functional import Tensor\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torch.utils.data import sampler, DataLoader, TensorDataset\n",
    "from typing import Dict, List, Sequence, Set, Text, Tuple, Union\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, fbeta_score, accuracy_score\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.metrics import geometric_mean_score \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from simpletransformers.config.model_args import ModelArgs\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def pickle_data(data, file_name):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "        \n",
    "def unpickle_data(data):\n",
    "    with open(data, \"rb\") as file:\n",
    "        loaded = pickle.load(file)\n",
    "    return loaded\n",
    "\n",
    "def reader(root: str, file: str):\n",
    "    with open(os.path.join(root, file), \"r\") as f: \n",
    "        return f.readlines()\n",
    "\n",
    "def json_r(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        loaded = json.load(file)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw files\n",
    "\n",
    "# get train, dev and test sets\n",
    "d2a_train = pd.read_csv(\"/Users/Gabriel/Projects/vReduce/data/d2a/function/train.csv\")\n",
    "d2a_dev = pd.read_csv(\"/Users/Gabriel/Projects/vReduce/data/d2a/function/train.csv\")\n",
    "d2a_test = pd.read_csv(\"/Users/Gabriel/Projects/vReduce/data/d2a/function/train.csv\")\n",
    "d2a_train_files, d2a_dev_files, d2a_test_files = list(d2a_train[\"code\"]), list(d2a_dev[\"code\"]), list(d2a_test[\"code\"]), \n",
    "d2a_train_labels, d2a_dev_labels = np.array(list(d2a_train[\"label\"])), np.array(list(d2a_dev[\"label\"]))\n",
    "\n",
    "# get asts but first compile c/c++ code\n",
    "def get_asts(project):\n",
    "    out = {}\n",
    "    for root, _, files in os.walk(project):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                source_file_pth = os.path.join(root, file) \n",
    "                source_file_name = int(pathlib.Path(source_file_pth).stem.split(\".\")[0])\n",
    "                try:\n",
    "                    with open(source_file_pth, \"r\") as source_file:\n",
    "                        out[source_file_name] = source_file.read()\n",
    "                except OSError as e:\n",
    "                    raise e\n",
    "    return list(OrderedDict(sorted(out.items())).values())\n",
    "\n",
    "# retrieve extracted asts\n",
    "d2a_train_asts = get_asts(\"/Users/Gabriel/Projects/vreduce/data/d2a/raw/train\")\n",
    "d2a_dev_asts = get_asts(\"/Users/Gabriel/Projects/vreduce/data/d2a/raw/dev\")\n",
    "d2a_test_asts = get_asts(\"/Users/Gabriel/Projects/OUR/data/d2a/raw/test\")\n",
    "\n",
    "# get features \n",
    "def extract_features(observations, features): # main\n",
    "    nodes = []\n",
    "    for observation in observations:\n",
    "        temp = []\n",
    "#         temp = data.split()\n",
    "        for data in observation.split():\n",
    "            if data.endswith(features):\n",
    "                temp.append(data)\n",
    "        nodes.append(temp)\n",
    "    out = []\n",
    "    for node in nodes:\n",
    "        temp = []\n",
    "        for feature in node:\n",
    "            temp.append(feature.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "        out.append(temp)\n",
    "    return out\n",
    "\n",
    "# d2a train features\n",
    "d2a_stmts, d2a_exprs, d2a_decls = extract_features(d2a_train_asts, \"Stmt\"), extract_features(d2a_train_asts, \"Expr\"), extract_features(d2a_train_asts, \"Decl\")\n",
    "d2a_train_features = (d2a_stmts, d2a_exprs, d2a_decls)\n",
    "pickle_data(d2a_train_features, \"/Users/Gabriel/Projects/vReduce/vreduce/selected/d2a/d2a_train_features.pkl\")\n",
    "\n",
    "\n",
    "d2a_stmts, d2a_exprs, d2a_decls = extract_features(d2a_dev_asts, \"Stmt\"), extract_features(d2a_dev_asts, \"Expr\"), extract_features(d2a_dev_asts, \"Decl\")\n",
    "d2a_dev_features = (d2a_stmts, d2a_exprs, d2a_decls)\n",
    "pickle_data(d2a_dev_features, \"/Users/Gabriel/Projects/vReduce/vreduce/selected/d2a/d2a_dev_features.pkl\")\n",
    "\n",
    "d2a_stmts, d2a_exprs, d2a_decls = extract_features(d2a_test_asts, \"Stmt\"), extract_features(d2a_test_asts, \"Expr\"), extract_features(d2a_test_asts, \"Decl\")\n",
    "d2a_test_features = (d2a_stmts, d2a_exprs, d2a_decls)\n",
    "pickle_data(d2a_test_features, \"/Users/Gabriel/Projects/vReduce/vreduce/selected/d2a/d2a_test_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2a_stmts, d2a_exprs, d2a_decl = d2a_train_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2a_train_1 = unpickle_data(\"/Users/Gabriel/Projects/vReduce/vreduce/features/d2a/one.pkl\")\n",
    "# d2a_train_2 = unpickle_data(\"/Users/Gabriel/Projects/vReduce/vreduce/features/d2a/two.pkl\")\n",
    "# d2a_train_3 = unpickle_data(\"/Users/Gabriel/Projects/vReduce/vreduce/features/d2a/three.pkl\")\n",
    "# d2a_train_4 = unpickle_data(\"/Users/Gabriel/Projects/vReduce/vreduce/features/d2a/four.pkl\")\n",
    "# d2a_train_5 = unpickle_data(\"/Users/Gabriel/Projects/vReduce/vreduce/features/d2a/five.pkl\")\n",
    "\n",
    "# # Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2a_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
